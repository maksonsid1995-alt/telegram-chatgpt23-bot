import os
import openai
import logging
import asyncio
from aiogram import Bot, Dispatcher, types
from aiogram.types import Update
from aiohttp import web
from tenacity import retry, stop_after_attempt, wait_fixed

# ======== –õ–û–ì–ò–†–û–í–ê–ù–ò–ï ========
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# ======== –ü–ï–†–ï–ú–ï–ù–ù–´–ï –û–ö–†–£–ñ–ï–ù–ò–Ø ========
BOT_TOKEN = os.getenv("BOT_TOKEN")
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")
PORT = int(os.environ.get("PORT", 10000))

if not BOT_TOKEN or not OPENAI_API_KEY:
    raise ValueError("–ù–µ –∑–∞–¥–∞–Ω—ã BOT_TOKEN –∏–ª–∏ OPENAI_API_KEY –≤ Environment Variables")

WEBHOOK_PATH = f"/webhook/{BOT_TOKEN}"
WEBHOOK_URL = f"https://telegram-chatgpt23-bot.onrender.com{WEBHOOK_PATH}"

# ======== –ò–ù–ò–¶–ò–ê–õ–ò–ó–ê–¶–ò–Ø ========
openai.api_key = OPENAI_API_KEY
bot = Bot(token=BOT_TOKEN)
dp = Dispatcher()

# ======== –§–£–ù–ö–¶–ò–ò ========
def split_message(text, limit=4000):
    """–†–∞–∑–¥–µ–ª–µ–Ω–∏–µ –¥–ª–∏–Ω–Ω–æ–≥–æ —Ç–µ–∫—Å—Ç–∞ –Ω–∞ —á–∞—Å—Ç–∏ –¥–ª—è Telegram."""
    return [text[i:i+limit] for i in range(0, len(text), limit)]

@retry(stop=stop_after_attempt(3), wait=wait_fixed(2))
def get_openai_response(prompt: str):
    """–ó–∞–ø—Ä–æ—Å –∫ OpenAI —Å –ø–æ–≤—Ç–æ—Ä–Ω—ã–º–∏ –ø–æ–ø—ã—Ç–∫–∞–º–∏ –ø—Ä–∏ —Å–±–æ—è—Ö."""
    return openai.ChatCompletion.create(
        model="gpt-3.5-turbo",
        messages=[{"role": "user", "content": prompt}]
    )

# ======== –ü–†–ò–í–ï–¢–°–¢–í–ò–ï –ù–û–í–´–• –ü–û–õ–¨–ó–û–í–ê–¢–ï–õ–ï–ô ========
@dp.message(commands=["start"])
async def welcome(message: types.Message):
    user_name = message.from_user.full_name
    greeting = (
        f"–ü—Ä–∏–≤–µ—Ç, {user_name}! üëã\n\n"
        "–Ø –±–æ—Ç —Å ChatGPT. –ú–æ–∂–µ—à—å –ø–∏—Å–∞—Ç—å –º–Ω–µ –ª—é–±—ã–µ –≤–æ–ø—Ä–æ—Å—ã, "
        "–∏ —è –ø–æ—Å—Ç–∞—Ä–∞—é—Å—å –¥–∞—Ç—å —Ä–∞–∑–≤—ë—Ä–Ω—É—Ç—ã–π –æ—Ç–≤–µ—Ç. üòä"
    )
    await message.answer(greeting)

# ======== –û–ë–†–ê–ë–û–¢–ö–ê –°–û–û–ë–©–ï–ù–ò–ô ========
@dp.message()
async def chatgpt_reply(message: types.Message):
    try:
        response = get_openai_response(message.text)
        text = response.choices[0].message["content"]
        for chunk in split_message(text):
            await message.answer(chunk)
    except Exception as e:
        await message.answer("–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ –∑–∞–ø—Ä–æ—Å–∞. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –ø–æ–∑–∂–µ.")
        logger.error(f"OpenAI error: {e}")

# ======== –ó–ê–ü–£–°–ö WEBHOOK ========
async def on_startup():
    """–£–¥–∞–ª—è–µ–º —Å—Ç–∞—Ä—ã–π webhook –∏ —Å—Ç–∞–≤–∏–º –Ω–æ–≤—ã–π."""
    await bot.delete_webhook(drop_pending_updates=True)
    await bot.set_webhook(WEBHOOK_URL)
    logger.info(f"Webhook —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω –Ω–∞ {WEBHOOK_URL}")

async def on_shutdown():
    """–û—á–∏—Å—Ç–∫–∞ webhook –ø—Ä–∏ –≤—ã–∫–ª—é—á–µ–Ω–∏–∏."""
    await bot.delete_webhook()
    logger.info("Webhook —É–¥–∞–ª—ë–Ω –ø—Ä–∏ shutdown")

async def main():
    # –°—Ç–∞—Ä—Ç webhook —Å–µ—Ä–≤–µ—Ä–∞
    await on_startup()
    await dp.start_webhook(
        webhook_path=WEBHOOK_PATH,
        host="0.0.0.0",
        port=PORT,
        bot=bot,
        on_shutdown=on_shutdown
    )

if __name__ == "__main__":
    asyncio.run(main())