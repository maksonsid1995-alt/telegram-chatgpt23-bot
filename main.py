import os
import logging
from aiohttp import web
from aiogram import Bot, Dispatcher, types
from aiogram.filters import Command
from openai import AsyncOpenAI

# ====== –õ–û–ì–ò ======
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# ====== –ù–ê–°–¢–†–û–ô–ö–ò ======
BOT_TOKEN = os.getenv("BOT_TOKEN")
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")
PORT = int(os.environ.get("PORT", 10000))

if not BOT_TOKEN or not OPENAI_API_KEY:
    raise ValueError("–ù–µ –∑–∞–¥–∞–Ω—ã BOT_TOKEN –∏–ª–∏ OPENAI_API_KEY –≤ Environment Variables")

WEBHOOK_PATH = f"/webhook/{BOT_TOKEN}"
WEBHOOK_URL = f"https://telegram-chatgpt23-bot.onrender.com{WEBHOOK_PATH}"

bot = Bot(token=BOT_TOKEN)
dp = Dispatcher()

openai_client = AsyncOpenAI(api_key=OPENAI_API_KEY)

# ====== –í–°–ü–û–ú–û–ì–ê–¢–ï–õ–¨–ù–´–ï –§–£–ù–ö–¶–ò–ò ======
def split_message(text, limit=4000):
    return [text[i:i + limit] for i in range(0, len(text), limit)]

async def get_openai_response(prompt: str):
    try:
        completion = await openai_client.chat.completions.create(
            model="gpt-3.5-turbo",
            messages=[{"role": "user", "content": prompt}]
        )
        return completion.choices[0].message.content
    except Exception as e:
        logger.exception(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞—â–µ–Ω–∏–∏ –∫ OpenAI API: {e}")
        return "‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞—â–µ–Ω–∏–∏ –∫ –º–æ–¥–µ–ª–∏. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –ø–æ–∑–∂–µ."

# ====== –û–ë–†–ê–ë–û–¢–ß–ò–ö–ò ======
@dp.message(Command("start"))
async def start_handler(message: types.Message):
    keyboard = types.ReplyKeyboardMarkup(
        keyboard=[[types.KeyboardButton(text="üí¨ –ó–∞–¥–∞—Ç—å –≤–æ–ø—Ä–æ—Å")]],
        resize_keyboard=True
    )
    await message.answer(
        f"–ü—Ä–∏–≤–µ—Ç, {message.from_user.full_name}! üëã\n–ù–∞–ø–∏—à–∏ –º–Ω–µ –≤–æ–ø—Ä–æ—Å, –∏ —è –ø–æ—Å—Ç–∞—Ä–∞—é—Å—å –æ—Ç–≤–µ—Ç–∏—Ç—å.",
        reply_markup=keyboard
    )

@dp.message()
async def message_handler(message: types.Message):
    text = message.text.strip()
    if not text:
        await message.answer("–ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –≤–≤–µ–¥–∏ —Ç–µ–∫—Å—Ç –∑–∞–ø—Ä–æ—Å–∞.")
        return

    await message.answer("‚è≥ –î—É–º–∞—é –Ω–∞–¥ –æ—Ç–≤–µ—Ç–æ–º...")
    response = await get_openai_response(text)

    for chunk in split_message(response):
        await message.answer(chunk)

# ====== –û–ë–†–ê–ë–û–¢–ö–ê WEBHOOK ======
async def handle(request):
    try:
        data = await request.json()
        logger.info(f"–ü–æ–ª—É—á–µ–Ω webhook: {data}")
        update = types.Update(**data)
        await dp.process_update(update)
        return web.Response(text="ok")
    except Exception as e:
        logger.exception(f"–û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –∑–∞–ø—Ä–æ—Å–∞: {e}")
        return web.Response(status=500, text="error")

# ====== –°–¢–ê–†–¢ / –û–°–¢–ê–ù–û–í–ö–ê ======
async def on_startup(app):
    await bot.delete_webhook(drop_pending_updates=True)
    await bot.set_webhook(WEBHOOK_URL)
    logger.info(f"Webhook —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω –Ω–∞ {WEBHOOK_URL}")

async def on_shutdown(app):
    await bot.delete_webhook()
    logger.info("Webhook —É–¥–∞–ª—ë–Ω –ø—Ä–∏ –∑–∞–≤–µ—Ä—à–µ–Ω–∏–∏ —Ä–∞–±–æ—Ç—ã")

# ====== –ó–ê–ü–£–°–ö ======
app = web.Application()
app.router.add_post(WEBHOOK_PATH, handle)
app.on_startup.append(on_startup)
app.on_cleanup.append(on_shutdown)

if __name__ == "__main__":
    web.run_app(app, host="0.0.0.0", port=PORT)
